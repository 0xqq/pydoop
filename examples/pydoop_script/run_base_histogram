#!/usr/bin/env python

# BEGIN_COPYRIGHT
# 
# Copyright 2012 CRS4.
# 
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License. You may obtain a copy
# of the License at
# 
#   http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
# 
# END_COPYRIGHT

import os, uuid, tempfile, shutil, logging
logging.basicConfig(level=logging.INFO)
import subprocess as sp

import pydoop.hdfs as hdfs

PYDOOP_EXE = "../../scripts/pydoop"
SCRIPT = "base_histogram.py"
LOCAL_INPUT = "example.sam"
HDFS_INPUT = uuid.uuid4().hex
HDFS_OUTPUT = uuid.uuid4().hex
LOCAL_OUTPUT = tempfile.mkdtemp()


def main():
  logging.info("copying data to HDFS")
  hdfs.put(LOCAL_INPUT, HDFS_INPUT)
  args = [
    PYDOOP_EXE,
    "script",
    SCRIPT,
    HDFS_INPUT,
    HDFS_OUTPUT,
    ]
  logging.info("running MapReduce application")
  retcode = sp.call(args)
  if retcode:
    raise RuntimeError("Error running pydoop_script")
  logging.info("checking results")
  hdfs.get(HDFS_OUTPUT, LOCAL_OUTPUT)
  for d in HDFS_INPUT, HDFS_OUTPUT:
    hdfs.rmr(d)
  output_dir = os.path.join(LOCAL_OUTPUT, HDFS_OUTPUT)
  out_fnames = sorted([os.path.join(output_dir, fn)
                       for fn in os.listdir(output_dir)
                       if fn.startswith("part-")])
  out_files = map(open, out_fnames)
  result = "".join(f.read() for f in out_files)
  for f in out_files:
    f.close()
  print result
  shutil.rmtree(LOCAL_OUTPUT)


if __name__ == "__main__":
  main()
