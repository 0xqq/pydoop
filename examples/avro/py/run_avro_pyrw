#!/usr/bin/env bash

# BEGIN_COPYRIGHT
#
# Copyright 2009-2017 CRS4.
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License. You may obtain a copy
# of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
#
# END_COPYRIGHT

set -euo pipefail
[ -n "${DEBUG:-}" ] && set -x
this="${BASH_SOURCE-$0}"
this_dir=$(cd -P -- "$(dirname -- "${this}")" && pwd -P)
. "${this_dir}/../../config.sh"

USER_SCHEMA_FILE="${this_dir}"/../schemas/user.avsc
STATS_SCHEMA_FILE="${this_dir}"/../schemas/stats.avsc
CSV_FN=users.csv
AVRO_FN=users.avro
OUTPUT=results

# --- generate avro input ---
N=20
${PYTHON} create_input.py ${N} "${CSV_FN}"
${PYTHON} write_avro.py "${USER_SCHEMA_FILE}" "${CSV_FN}" "${AVRO_FN}"
${HADOOP} fs -mkdir -p /user/"${USER}"
${HADOOP} fs -rm "${AVRO_FN}" || :
${HADOOP} fs -put "${AVRO_FN}"

# --- run cc ---
MODULE=avro_pyrw
MPY="${MODULE}".py
JOBNAME="${MODULE}"-job
LOGLEVEL="DEBUG"
INPUT="${AVRO_FN}"

${HADOOP} fs -rmr "/user/${USER}/${OUTPUT}" || :
${PYDOOP} submit \
    --upload-file-to-cache "${MPY}" \
    --upload-file-to-cache "${USER_SCHEMA_FILE}" \
    --upload-file-to-cache "${STATS_SCHEMA_FILE}" \
    --num-reducers 1 \
    -D mapreduce.pipes.isjavarecordreader=false \
    -D mapreduce.pipes.isjavarecordwriter=false \
    --log-level "${LOGLEVEL}" \
    --job-name "${JOBNAME}" \
    "${MODULE}" "${INPUT}" "${OUTPUT}"

# --- dump & check results ---
DUMP_FN=stats.tsv
rm -rf "${OUTPUT}"
${HADOOP} fs -get "${OUTPUT}"
${PYTHON} avro_container_dump_results.py \
    "${OUTPUT}"/part-r-00000.avro "${DUMP_FN}"
${PYTHON} check_results.py "${CSV_FN}" "${DUMP_FN}"
