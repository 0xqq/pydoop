#!/usr/bin/env bash

# BEGIN_COPYRIGHT
#
# Copyright 2009-2017 CRS4.
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License. You may obtain a copy
# of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
#
# END_COPYRIGHT

set -euo pipefail
[ -n "${DEBUG:-}" ] && set -x
this="${BASH_SOURCE-$0}"
this_dir=$(cd -P -- "$(dirname -- "${this}")" && pwd -P)
. "${this_dir}/../config.sh"

MODULE="col0"
MPY="${MODULE}".py
JOBNAME="${MODULE}"-job
INPUT="${MODULE}"_input
OUTPUT="${MODULE}"_output
LOGLEVEL="DEBUG"
OUTPUT_FORMAT="it.crs4.pydoop.NoSeparatorTextOutputFormat"

cat >"${MPY}" <<EOF
import sys
import pydoop.mapreduce.api as api
import pydoop.mapreduce.pipes as pp

class Mapper(api.Mapper):
    def map(self, ctx):
        p = ctx.value.strip().split(b'\t')
        ctx.emit(p[0], p[1])

def __main__():
    factory = pp.Factory(Mapper, None)
    pp.run_task(factory)
EOF

cat >"${INPUT}" <<EOF
foo1	bar1
foo2	bar2
foo3	bar3
foo4	bar4
EOF

${HADOOP} fs -rmr "/user/${USER}/${INPUT}" || :
${HADOOP} fs -mkdir -p "/user/${USER}/${INPUT}"
${HADOOP} fs -rmr "/user/${USER}/${OUTPUT}" || :
${HADOOP} fs -put "${INPUT}" "${INPUT}"

${PYDOOP} submit \
  --python-program "${PYTHON}" \
  --upload-file-to-cache "${MPY}" \
  --num-reducers 0 \
  --output-format "${OUTPUT_FORMAT}" \
  --log-level ${LOGLEVEL} \
  --job-name ${JOBNAME} \
  "${MODULE}" "${INPUT}" "${OUTPUT}"

rm -rf "${OUTPUT}"
${HADOOP} fs -get "${OUTPUT}"
tr -d "\t" < "${INPUT}" | sort > col0.A
sort "${OUTPUT}"/part-m-00000 > col0.B
r=$(diff col0.A col0.B)
if [ -z "${r}" ]; then RES="OK" ; else RES="NOT OK" ; fi
echo "result is: ${RES}."
