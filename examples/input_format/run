#!/usr/bin/env python

# BEGIN_COPYRIGHT
# 
# Copyright 2012 CRS4.
# 
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License. You may obtain a copy
# of the License at
# 
#   http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
# 
# END_COPYRIGHT

"""
Test overriding of RecordReader provided by InputFormat.

You can use a custom Java InputFormat with a Python RecordReader: the
RecordReader supplied by the InputFormat will be overridden by the
Python one. Just remember to set 'hadoop.pipes.java.recordreader' to
'false' (try to run this with --java-rr and see how it crashes).

The example custom InputFormat is a simple modification of the
standard TextInputFormat: it adds a configurable boolean parameter
that, if set to 'false', makes input file non-splitable (i.e., you
can't get more InputSplits than the number of input files).
"""

import sys, os, optparse, uuid, logging
logging.basicConfig(level=logging.INFO)

from pydoop.hadoop_utils import get_hadoop_exec
import pydoop.hdfs as hdfs
import pydoop.test_support as pts
import pydoop.hadut as hadut

import compiler


HADOOP = get_hadoop_exec()
LOCAL_MR_SCRIPT = "wordcount-rr.py"
THIS_DIR = os.path.dirname(os.path.abspath(__file__))
DEFAULT_INPUT = os.path.normpath(os.path.join(THIS_DIR, "../input"))
OUTPUT = "output"
INPUT_FORMAT = "net.sourceforge.pydoop.mapred.TextInputFormat"
JAR_NAME = "pydoop-mapred.jar"
CONF = {
  "mapred.job.name": "test_rr_override",
  "mapreduce.admin.user.home.dir": os.path.expanduser("~"),
  "hadoop.pipes.java.recordreader": "false",
  "hadoop.pipes.java.recordwriter": "true",
  "mapred.input.format.class": INPUT_FORMAT,
  }


class HelpFormatter(optparse.IndentedHelpFormatter):
  def format_description(self, description):
    return description + "\n" if description else ""


def make_parser():
  parser = optparse.OptionParser(
    usage="%prog [OPTIONS]", formatter=HelpFormatter(),
    )
  parser.set_description(__doc__.lstrip())
  parser.add_option("-i", dest="input", metavar="STRING",
                    help="input dir ['%default']", default=DEFAULT_INPUT)
  parser.add_option("--java-rr", action="store_true",
                    help="Java RecordReader (CRASHES THE APPLICATION)")
  parser.add_option("--splitable", action="store_true",
                    help="allow input format to split individual files")
  parser.add_option("--clean", action="store_true",
                    help="do not run the example. Perform cleanup")
  return parser


def main():

  parser = make_parser()
  opt, _ = parser.parse_args()
  
  if opt.clean:
    os.system("find . -regex '.*\(\.class\|~\|.pyc\)' -exec rm -fv {} \;")
    os.system("rm -rfv *.jar %s" % OUTPUT)
    return 0

  logging.info("compiling Java code")
  retval = compiler.main(["compiler.py", JAR_NAME])
  if retval:
    return retval

  logging.info("copying data to HDFS")
  wd = "pydoop_test_input_format_%s" % uuid.uuid4().hex
  hdfs.mkdir(wd)
  mr_script = hdfs.path.join(wd, os.path.basename(LOCAL_MR_SCRIPT))
  with open(LOCAL_MR_SCRIPT) as f:
    pipes_code = pts.add_sys_path(f.read())
  hdfs.dump(pipes_code, mr_script)
  input_ = hdfs.path.join(wd, os.path.basename(opt.input))
  hdfs.put(opt.input, input_)
  output = hdfs.path.join(wd, uuid.uuid4().hex)

  logging.info("running MapReduce application")
  conf = CONF.copy()
  if opt.java_rr:
    conf["hadoop.pipes.java.recordreader"] = "true"
  conf["pydoop.input.issplitable"] = "true" if opt.splitable else "false"
  jar_opt = ["-libjars", JAR_NAME]
  hadut.run_pipes(mr_script, input_, output, more_args=jar_opt, properties=conf)

  logging.info("checking results")
  res = pts.collect_output(output)
  for d in mr_script, input_, output:
    hdfs.rmr(d)
  local_wc = pts.LocalWordCount(opt.input)
  logging.info(local_wc.check(res))

  return 0


if __name__ == "__main__":
  sys.exit(main())
