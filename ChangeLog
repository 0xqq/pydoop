2010-08-06    <simleo@neuron.crs4.it>

	* setup.py: added platforms and license metadata. Note that the
	Makefile (and the copyrighter script it uses) has not been updated
	to include the Apache 2.0 notice yet.

	* pydoop/utils.py (_HdfsPathSplitter.split): fixed a bug that was
	causing it to allow colons in some hdfs paths; error messages now
	provide more details on what went wrong.

2010-08-04    <simleo@neuron.crs4.it>

	* pydoop/utils.py (_HdfsPathSplitter.split): bad url exception now
	reports bad url name.

	* pydoop/hdfs.py (hdfs.__init__): user can now be None, with the
	same effect as "".

2010-07-29    <simleo@neuron.crs4.it>

	* pydoop/utils.py (split_hdfs_path): rewritten to eliminate
	urlparse dependency (fixes ticket #316).

2010-07-23    <simleo@neuron.crs4.it>

	* pydoop/hdfs.py (hdfs_file.read): fixed #319.

2010-07-20    <simleo@neuron.crs4.it>

	* pydoop/hdfs.py (hdfs_file.read): fixed #312.

2010-07-07    <simleo@neuron.crs4.it>

	* docs/conf.py: version and release are now dynamically retrieved
	from pydoop/__init__.py.

2010-07-05    <simleo@neuron.crs4.it>

	* src/hdfs_file.hpp, src/hdfs_file.cpp, pydoop/hdfs.py: added flush.

	* src/hdfs_fs.hpp, src/hdfs_fs.cpp, pydoop/hdfs.py: added utime.

2010-07-02    <simleo@neuron.crs4.it>

	* src/hdfs_fs.hpp, src/hdfs_fs.cpp, pydoop/hdfs.py: added chown
	and chmod.

2010-07-01    <simleo@neuron.crs4.it>

	* pydoop/__init__.py (__version__): changed from "0.3.6-dev" to
	"0.3.6_rc1". This allows us to build internal releases that are
	compliant with Gentoo's file naming rules, see
	http://devmanual.gentoo.org/ebuild-writing/file-format/index.html.
	The main advantage is that "0.3.6_rc2", ..., "0.3.6_rcN", "0.3.6"
	will automatically be considered upgrades by portage.

	* pydoop/hdfs.py (hdfs.__init__): changed to match changes in the
	underlying C++ constructor.

	* src/hdfs_fs.hpp (wrap_hdfs_fs): changed to wrap
	hdfsConnectAsUser. It falls back to the old behavior if user is an
	empty string and groups an empty list.

2010-06-29    <simleo@neuron.crs4.it>

	* setup.py: Removed BoostExtFactory, added BoostExtension. The
	latter is a subclass of Extension that can be directly passed to
	the setup function as a member of the ext_modules list, with
	additional methods to build main files and patched aux files.
	Together with the newly added "build_boost_ext" command, this
	fixes #191. Note that auto-generated files must still be excluded
	in MANIFEST.in because the dist tarball is built after the docs
	have been built and these, in turn, require package build.
	(create_pipes_ext, create_hdfs_ext): changed module names to fix
	#310. Imports in all python modules have been changed accordingly.

2010-06-25    <simleo@neuron.crs4.it>

	* pydoop/utils.py: removed __cleanup_file_path, it is no longer used.
	(split_hdfs_path): fixed #260.

	* examples/text_pipe_runner.py: changed to take pipes executable
	as an input parameter.

	* docs/conf.py: fixed sys.path manipulation to import from build dir.

	* Makefile: refactored to support Sphinx docs; added more targets.

2010-06-24    <simleo@neuron.crs4.it>

	* pydoop/hdfs.py (hdfs): added wrappers to all remaining methods,
	with docstrings for Sphinx.

2010-02-25    <simleo@neuron.crs4.it>

	* src/HadoopPipes_signal.cpp: this is currently experimental, so
	it's not distributed and disabled (a 'signal_setup_hack.diff' file
	has been added to the root dir that shows how to re-enable it).

2010-02-09    <simleo@neuron.crs4.it>

	* src/pipes.hpp: all destructors made virtual.

	* src/hdfs_fs.cpp (list_directory): fixed #262.

2010-02-03    <simleo@neuron.crs4.it>

	* pydoop: added epydoc markup for main modules.

2010-02-01    <simleo@neuron.crs4.it>

	* src/hdfs_fs.cpp (get_path_info): fixed #261. The
	'exec_and_trap_error' macro does not work here, error is signaled
	by a NULL result, not negative. Also fixed analogous bugs in
	list_directory and get_working_directory; unit tests updated
	accordingly (except for get_working_directory: how do we get it to
	fail on this?)

2009-12-23    <zag@pflip>

	* test/test_hdfs_basic_class.py (hdfs_basic_tc.copy_on_self):
	added test to check copy on self.

	* pydoop/text_protocol.py (text_down_protocol): minor clean up in
	__send()

2009-12-15    <zag@pflip>

	* setup.py (OLD_WRITE_BUFFER): Fixed a bug (#250) in HadoopPipes
	due to a bad use of fprintf. This should be escalated upstream to
	hadoop.

2009-12-14    <simleo@neuron.crs4.it>

	* src/hdfs_fs.cpp (get_path_info): changed to wrap hdfsGetPathInfo.
	Fixes #249.

2009-12-13    <zag@pflip>

	* src/pipes_serial_utils.cpp (export_pipes_serial_utils):
	added {quote,unquote}_string. Exported via pydoop.utils.

	* pydoop/text_protocol.py (text_down_protocol.set_job_conf): Fixed
	a stupid % formatting mistake.

2009-12-12    <zag@pflip>

	* MANIFEST.in: added pipes_runner support.

2009-11-16    <simleo@neuron.crs4.it>

	* pydoop/hdfs.py (hdfs_file.seek): changed to reset
	readline-related values. Fixes #239.

2009-10-28    <simleo@neuron.crs4.it>

	* examples/bin/wordcount-full.py (WordCountReader): changed to
	output file byte offset as key (mimic Hadoop default).
	(WordCountWriter): added.
	(WordCountPartitioner): added.

2009-10-27    <simleo@neuron.crs4.it>

	* README.txt: added section on running unit tests.

	* MANIFEST.in: put in sync with what we have and want to release.

	* examples: basic python example renamed to wordcount-minimal.py;
	added wordcount-full.py, where we want to demonstrate (almost) all
	pydoop features. For now it includes a Python RecordReader that
	replaces the standard Java line reader.

	* pydoop/hdfs.py: added hdfs_file as a wrapper around the
	underlying cpp object. Adds the readline method.

2009-10-26    <simleo@neuron.crs4.it>

	* pydoop/pipes.py: Task components (Mapper, Reducer etc.)
	explicitly redefined as abstract classes (fixes # 236).
	Constructors now accept an optional context object that's not
	used (__init__ must be explicitly overridden, and the user is
	likely to expect the base class to accept a context object too).

2009-10-20    <lsimleo@neuron.crs4.it>

	* setup.py: changed to use the pre-compiled libhdfs. NOTE: only
	Hadoop 0.20 is supported now.
	(create_pipes_ext): changed to generate auxiliary files by copying
	them from the Hadoop installation and applying necessary patches.

2009-10-07    <lsimleo@neuron.crs4.it>

	* src/hdfs_file.cpp (write): changed to use a reference to the buffer.

	* test/test_hdfs_network.py: added tests for block size & replication.

2009-09-28    <zag@manzanillo>

	* src/SerialUtils.cpp (HadoopUtils): deserializeFloat put in phase
	with hadoop-0.19 header files.

	* src/pipes_serial_utils.cpp: Added basic functions to access
	hadoop serialization.

2009-09-27    <zag@manzanillo>

	* setup.py: Bumped to 0.2.5 (added support for application testing)

	* pydoop/pipes_runner.py (pipes_runner): Added a driver for
	application testing.

	* pydoop/text_protocol.py: Added support to directly talk pipes
	textual protocol.

	* pydoop/utils.py (make_input_split): Added a function to
	build input splits.

2009-09-22    <zag@manzanillo>

	* setup.py: Bumped to version 0.2.4

	* test/test_utils.py (utils_tc.split): updated to the new
	split_hdfs_path.

	* pydoop/utils.py (split_hdfs_path): Changed function
	internals. Now we follow the python way and use internal
	batteries (i.e. urlparse)
 
2009-09-21    <zag@manzanillo>

	* pydoop/utils.py (split_hdfs_path): Added handling of file:/// files.

	* pydoop/utils.py (jc_configure_float): added.

	* pydoop/pipes.py: now we export {Task,Map,Reduce}Context too.


2009-08-28    <zag@manzanillo.crs4.it>

	* setup.py: Bumped to version 0.2.3.

	* test/test_utils.py: added some testing.

	* pydoop/utils.py: using raise_pydoop_exception to raise what (I
	hope) will be a c++ compatible exception. It is probably the wrong thing to do. 

	* test/test_exceptions.py: added some basic tests for the new exceptions.

	* src/exceptions.cpp: Added. Contains translators that prepend the
	exception name to the exception message. Better than nothing. We
	currently support 'pydoop_exception' and 'pydoop_exception.pipes'.

	* src/exceptions.hpp: Added. All our c++ exception are now defined
	here. They will all be described as 'exception.UserWarning'

	* src/Makefile (machine): replaced machine=`uname -a` with machine=$(shell uname -m)

	* src/pipes_context.hpp: Removed horrible_hack. Now we simply do
	an incref on the string object. Basically, we are creating a
	memory leak inside python :-(. I do not see a clean way around
	this.

2009-08-13    <lsimleo@neuron.crs4.it>

	* src/pipes.hpp: added Py_REFCNT macro to make it work with Python
	2.5.

	* test/test_hdfs_basic_class.py: added assertRaises tests for
	IOError.

	* src/Makefile (PIPES_AUX_FILES): removed hacked_wrapper (the
	source file has been removed in an earlier version).

	* test/test_factory.py (factory_tc.test_map_reduce_factory):
	changed to clean up refs before performing test.

2009-08-10    <lsimleo@neuron.crs4.it>

	* src/hdfs_common.cpp: created. Adds hdfs_exception mapping to
	Python IOError.

2009-08-09    <zag@manzanillo>

	* pydoop/: Clean up.

	* src/: All test support stuff in pipes.{c,h}pp has been moved to
	pipes_test_support.{c,h}pp

	* test/test_factory.py (factory_tc.test_map_reduce_factory):
	Preparing to test C++ destruction.

2009-07-08    <lsimleo@neuron.crs4.it>

	* setup.py: updated to build hadoop_hdfs. Distutils sucks.

2009-07-07    <lsimleo@neuron.crs4.it>

	* setup.py: added auto main generation for boost extensions (as in
	src/Makefile). Updated to build pydoop_pipes.

2009-07-06    <lsimleo@neuron.crs4.it>

	* src/libhdfs/Makefile: slight generalization.

2009-07-03    <lsimleo@neuron.crs4.it>

	* src/{SerialUtils,HadoopPipes,StringUtils}.cpp: fixed includes.

2009-05-14    <lsimleo@neuron.crs4.it>

	* pydoop.py (Factory.createMapper): removed debug lines.
