diff --git a/org/apache/hadoop/mapred/pipes/Application.java b/org/apache/hadoop/mapred/pipes/Application.java
index 9d41dc3..f3e405d 100644
--- a/org/apache/hadoop/mapred/pipes/Application.java
+++ b/org/apache/hadoop/mapred/pipes/Application.java
@@ -48,6 +48,7 @@ import org.apache.hadoop.mapred.RecordReader;
 import org.apache.hadoop.mapred.Reporter;
 import org.apache.hadoop.mapred.TaskAttemptID;
 import org.apache.hadoop.mapred.TaskLog;
+import org.apache.hadoop.mapred.TaskTracker;
 import org.apache.hadoop.mapreduce.security.SecureShuffleUtils;
 import org.apache.hadoop.mapreduce.security.TokenCache;
 import org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier;
@@ -95,14 +96,21 @@ class Application<K1 extends WritableComparable, V1 extends Writable,
     env.put("hadoop.pipes.command.port", 
             Integer.toString(serverSocket.getLocalPort()));
     
+    TaskAttemptID taskid = TaskAttemptID.forName(conf.get("mapred.task.id"));
+
+    // get the task's working directory
+    String workDir = TaskTracker.getLocalTaskDir(conf.getUser(),
+            taskid.getJobID().toString(),
+            taskid.getTaskID().toString());
+
     //Add token to the environment if security is enabled
     Token<JobTokenIdentifier> jobToken = TokenCache.getJobToken(conf
         .getCredentials());
     // This password is used as shared secret key between this application and
     // child pipes process
     byte[]  password = jobToken.getPassword();
-    String localPasswordFile = new File(".") + Path.SEPARATOR
-        + "jobTokenPassword";
+
+    String localPasswordFile = new File(workDir, "jobTokenPassword").getAbsolutePath();
     writePasswordToLocalFile(localPasswordFile, password, conf);
     env.put("hadoop.pipes.shared.secret.location", localPasswordFile);
  
@@ -120,7 +128,6 @@ class Application<K1 extends WritableComparable, V1 extends Writable,
     }
     cmd.add(executable);
     // wrap the command in a stdout/stderr capture
-    TaskAttemptID taskid = TaskAttemptID.forName(conf.get("mapred.task.id"));
     // we are starting map/reduce task of the pipes job. this is not a cleanup
     // attempt. 
     File stdout = TaskLog.getTaskLogFile(taskid, false, TaskLog.LogName.STDOUT);
