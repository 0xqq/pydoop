jdk: 
- oraclejdk7
after_success: 
- cd examples
- ./run_all
- cd ../
- sudo apt-get install debhelper python-all-dev libboost-python-dev libssl-dev python-sphinx devscripts inkscape
- make debian
- cd sandbox
- python -c "import smtplib, glob;from email.mime.application import MIMEApplication;from email.mime.multipart import MIMEMultipart;from email.mime.text import MIMEText;fromaddr = 'travis.ci.rs4@gmail.com';toaddrs  = 'travis.ci.rs4@gmail.com';msg = MIMEMultipart();msg['Subject'] = 'New pydoop deb for $HADOOPVERSION build:$TRAVIS_BUILD_NUMBER';msg['From'] = 'travis.ci.rs4@gmail.com';msg['To'] = 'travis.ci.rs4@gmail.com';username = 'travis.ci.rs4';password = '$pw';part = MIMEText(msg['Subject']);msg.attach(part);deb_file_name = glob.glob('*.deb')[0];part = MIMEApplication(open(deb_file_name,'rb').read());part.add_header('Content-Disposition', 'attachment', filename=deb_file_name);msg.attach(part);server = smtplib.SMTP('smtp.gmail.com:587');server.starttls();server.login(username,password);server.sendmail(msg['From'], msg['To'], msg.as_string());server.quit()"
env: 
  global: 
    secure: d1kOuK3dSEs2nNZdGFNcY9KLI5PuWOv7xq9V1b+/+rzhi/BezsvEAjRw+7SeVa/sBk5LcKuKtW06Mjst0npXk487TpQpuLSNzUbX1aaTw4+oG0iJWKeK559iiMs+MBSFYvC6XPts5DkNM+hn5KmhuzCTHBotCv7ZB9Zmuj/ULsg=
  matrix: 
  - HADOOPVERSION=0.20.2
  - HADOOPVERSION=cdh3u4
  - HADOOPVERSION=cdh3u5
  - HADOOPVERSION=1.0.4
  - HADOOPVERSION=1.1.2
  - HADOOPVERSION=1.2.1
  - HADOOPVERSION=2.2.0
  - HADOOPVERSION=cdh4.2.0
  - HADOOPVERSION=cdh4.3.0
  - HADOOPVERSION=cdh4.4.0
  - HADOOPVERSION=cdh4.5.0
python: 
- "2.7"
install:
- export LD_PRELOAD=/lib/x86_64-linux-gnu/libssl.so.1.0.0
- python setup.py install
before_install: 
- sudo apt-get install build-essential python-all-dev libboost-python-dev libssl-dev
- ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
- cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
- echo NoHostAuthenticationForLocalhost=yes >> ~/.ssh/config
- sudo groupadd admin
- sudo usermod  -a -G admin $USER
- groups $USER
- if [[ "$HADOOPVERSION" != *cdh* ]]; then wget http://archive.apache.org/dist/hadoop/core/hadoop-$HADOOPVERSION/hadoop-$HADOOPVERSION.tar.gz; fi
- if [[ "$HADOOPVERSION" != *cdh* ]]; then tar xf hadoop-$HADOOPVERSION.tar.gz; fi
- if [[ "$HADOOPVERSION" != *cdh* ]]; then export HADOOP_HOME=`pwd`/hadoop-$HADOOPVERSION; fi
- if [[ "$HADOOPVERSION" == 2.2.* ]]; then export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop; export HADOOP_BIN=$HADOOP_HOME/sbin; export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_HOME}/lib/native; export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib";else if [[ "$HADOOPVERSION" != *cdh* ]]; then export HADOOP_CONF_DIR=$HADOOP_HOME/conf; export HADOOP_BIN=$HADOOP_HOME/bin; fi; fi
- if [[ "$HADOOPVERSION" == 2.2.* ]]; then echo "<?xml version=\"1.0\"?> <configuration> <property> <name>yarn.resourcemanager.resource-tracker.address</name> <value>localhost:9050</value> <description>host is the hostname of the resource manager and port is the port on which the NodeManagers contact the Resource Manager. </description> </property>  <property> <name>yarn.resourcemanager.scheduler.address</name> <value>localhost:9051</value> <description>host is the hostname of the resourcemanager and port is the port on which the Applications in the cluster talk to the Resource Manager. </description> </property>  <property> <name>yarn.resourcemanager.scheduler.class</name> <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value> <description>In case you do not want to use the default scheduler</description> </property>  <property> <value>localhost:9052</value> <name>yarn.resourcemanager.address</name> <description>the host is the hostname of the ResourceManager and the port is the port on which the clients can talk to the Resource Manager. </description> </property>  <property> <name>yarn.nodemanager.local-dirs</name> <value>/tmp/nodemanager</value> <description>the local directories used by the nodemanager</description> </property>  <property> <name>yarn.nodemanager.address</name> <value>localhost:9053</value> <description>the nodemanagers bind to this port</description> </property>  <property> <name>yarn.nodemanager.resource.memory-mb</name> <value>10240</value> <description>the amount of memory on the NodeManager in GB</description> </property>  <property> <name>yarn.nodemanager.remote-app-log-dir</name> <value>/tmp/app-logs</value> <description>directory on hdfs where the application logs are moved to </description> </property> <property> <name>yarn.nodemanager.aux-services</name> <value>mapreduce_shuffle</value> <description>shuffle service that needs to be set for Map Reduce to run </description> </property> </configuration>" > $HADOOP_CONF_DIR/yarn-site.xml; fi
- if [[ "$HADOOPVERSION" != *cdh* ]]; then echo "<?xml version=\"1.0\"?><?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?><configuration><property><name>dfs.permissions.supergroup</name><value>admin</value></property><property><name>dfs.replication</name><value>1</value></property><property><name>dfs.namenode.fs-limits.min-block-size</name><value>512</value></property><property><name>dfs.namenode.secondary.http-address</name><value>localhost:50090</value></property></configuration>" > $HADOOP_CONF_DIR/hdfs-site.xml; fi
- if [[ "$HADOOPVERSION" != *cdh* ]]; then echo "<?xml version=\"1.0\"?><?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?><configuration><property><name>fs.default.name</name><value>hdfs://localhost:9000</value></property></configuration>" > $HADOOP_CONF_DIR/core-site.xml; fi
- if [[ "$HADOOPVERSION" != *cdh* ]]; then echo "<?xml version=\"1.0\"?><?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?><configuration> <property><name>mapred.job.tracker</name><value>localhost:9001</value></property></configuration>" > $HADOOP_CONF_DIR/mapred-site.xml; fi
- if [[ "$HADOOPVERSION" != *cdh* ]]; then $HADOOP_HOME/bin/hadoop namenode -format; fi
- if [[ "$HADOOPVERSION" != *cdh* ]]; then $HADOOP_BIN/start-all.sh; fi
- if [[ "$HADOOPVERSION" != *cdh* ]]; then $HADOOP_HOME/bin/hadoop dfsadmin -safemode wait; fi
- if [[ "$HADOOPVERSION" == *cdh* ]]; then mkdir -p /tmp/hadoop-hdfs/dfs/name; fi
- if [[ "$HADOOPVERSION" == *cdh* ]]; then chmod 777 /tmp/hadoop-hdfs/ -R; fi
- if [[ "$HADOOPVERSION" == *cdh* ]]; then ls -la /tmp/hadoop-hdfs/dfs/name; fi
- if [[ "$HADOOPVERSION" == *cdh4* ]]; then sudo add-apt-repository "deb [arch=amd64] http://archive.cloudera.com/cdh4/ubuntu/precise/amd64/cdh precise-$HADOOPVERSION contrib";  curl -s http://archive.cloudera.com/cdh4/ubuntu/lucid/amd64/cdh/archive.key | sudo apt-key add -; fi
- if [[ "$HADOOPVERSION" == *cdh3* ]]; then sudo add-apt-repository "deb [arch=amd64] http://archive.cloudera.com/debian lucid-$HADOOPVERSION contrib";  curl -s http://archive.cloudera.com/debian/archive.key | sudo apt-key add -; fi
- if [[ "$HADOOPVERSION" == *cdh4* ]]; then sudo apt-get update; sudo apt-get install hadoop-0.20-mapreduce-jobtracker hadoop-hdfs-datanode hadoop-hdfs-namenode hadoop-hdfs-secondarynamenode hadoop-client; fi
- if [[ "$HADOOPVERSION" == *cdh3* ]]; then sudo apt-get update; sudo apt-get install hadoop-0.20-conf-pseudo; fi
- if [[ "$HADOOPVERSION" == *cdh* ]]; then sudo chmod 666 /etc/hadoop/conf/*.xml; fi
- if [[ "$HADOOPVERSION" == *cdh* ]]; then sudo echo "<?xml version=\"1.0\"?><?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?><configuration><property><name>fs.default.name</name><value>hdfs://localhost:8020</value></property><!-- OOZIE proxy user setting --><property><name>hadoop.proxyuser.oozie.hosts</name><value>*</value></property><property><name>hadoop.proxyuser.oozie.groups</name><value>*</value></property><!-- HTTPFS proxy user setting --><property><name>hadoop.proxyuser.httpfs.hosts</name><value>*</value></property><property><name>hadoop.proxyuser.httpfs.groups</name><value>*</value></property></configuration>" > /etc/hadoop/conf/core-site.xml; fi
- if [[ "$HADOOPVERSION" == *cdh* ]]; then sudo sed '/\/configuration/ i\<property><name>dfs.permissions.supergroup<\/name><value>admin<\/value><\/property>' <  /etc/hadoop/conf/hdfs-site.xml > /tmp/hdfs-site.xml; sudo mv /tmp/hdfs-site.xml /etc/hadoop/conf/hdfs-site.xml; fi
- if [[ "$HADOOPVERSION" == *cdh* ]]; then sed "s/localhost /localhost `hostname` /" /etc/hosts > /tmp/hosts; sudo mv /tmp/hosts /etc/hosts;fi
- if [[ "$HADOOPVERSION" == *cdh* ]]; then sudo /etc/init.d/networking restart; fi
- if [[ "$HADOOPVERSION" == *cdh* ]]; then sudo -u hdfs hadoop namenode -format -force; fi
- if [[ "$HADOOPVERSION" == *cdh4* ]]; then sudo service hadoop-hdfs-datanode restart; sudo service hadoop-hdfs-namenode restart; fi
- if [[ "$HADOOPVERSION" == *cdh3* ]]; then JH=${JAVA_HOME//\//\\\/};sed "s/# export JAVA_HOME=.*/ export JAVA_HOME=${JH//\//\\\/}/" /etc/hadoop/conf/hadoop-env.sh > /tmp/env.sh; sudo mv /tmp/env.sh /etc/hadoop/conf/hadoop-env.sh; fi
- if [[ "$HADOOPVERSION" == *cdh3* ]]; then sudo service hadoop-0.20-datanode restart; sudo service hadoop-0.20-namenode restart; fi
- if [[ "$HADOOPVERSION" == *cdh* ]]; then hadoop dfsadmin -safemode wait; fi
- if [[ "$HADOOPVERSION" == *cdh* ]]; then hdfs="sudo -u hdfs hadoop fs"; ${hdfs} -mkdir /tmp; ${hdfs} -chmod 1777 /tmp; ${hdfs} -mkdir /var/lib/hadoop-hdfs/cache/mapred/mapred/staging; ${hdfs} -chmod 1777 /var/lib/hadoop-hdfs/cache/mapred/mapred/staging; ${hdfs} -chown -R mapred /var/lib/hadoop-hdfs/cache/mapred;${hdfs} -mkdir  /user/$USER;${hdfs} -chown $USER /user/$USER;fi

script: 
- python test/all_tests.py
language: python
